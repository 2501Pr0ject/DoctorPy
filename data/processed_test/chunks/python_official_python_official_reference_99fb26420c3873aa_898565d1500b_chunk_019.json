{
  "chunk_id": "python_official_python_official_reference_99fb26420c3873aa_898565d1500b_chunk_019",
  "original_doc_id": "python_official_python_official_reference_99fb26420c3873aa_898565d1500b",
  "content": "append(l[i:i+1] + x) return r # error: inconsistent dedent return r A Z _ 0 9 unicodedata identifier ::= xid_start xid_continue* id_start ::= <all characters in general categories Lu, Ll, Lt, Lm, Lo, Nl, the underscore, and characters with the Other_ID_Start property> id_continue ::= <all characters in id_start, plus characters in the categories Mn, Mc, Nd, Pc and others with the Other_ID_Continue property> xid_start ::= <all characters in id_start whose NFKC normalization is in \"id_start xid_continue*\"> xid_continue ::= <all characters in id_continue whose NFKC normalization is in \"id_continue*\"> xid_start xid_continue id_start id_start id_continue False await else import pass None break except in raise True class finally is return and continue for lambda try as def from nonlocal while assert del global not with async elif if or yield match case type _ match case _ match type type type _* from module import * _ case match _ _ builtins print _ _ gettext __*__ __*__ __* stringliteral ::= stringprefix stringprefix ::= \"r\" | \"u\" | \"R\" | \"U\" | \"f\" | \"F\" | \"fr\" | \"Fr\" | \"fR\" | \"FR\" | \"rf\" | \"rF\" | \"Rf\" | \"RF\" shortstring ::= \"'\" shortstringitem* \"'\" | '\"' shortstringitem* '\"' longstring ::= \"'''\" longstringitem* \"'''\" | '\"\"\"' longstringitem* '\"\"\"' shortstringitem ::= shortstringchar | stringescapeseq longstringitem ::= longstringchar | stringescapeseq shortstringchar ::= <any source character except \"\\\" or newline or the quote> longstringchar ::= <any source character except \"\\\"> stringescapeseq ::= \"\\\" <any source character> stringprefix shortstring longstring shortstringitem shortstringitem longstringitem longstringitem shortstringchar stringescapeseq longstringchar stringescapeseq bytesliteral ::= bytesprefix(shortbytes | longbytes) bytesprefix ::= \"b\" | \"B\" | \"br\" | \"Br\" | \"bR\" | \"BR\" | \"rb\" | \"rB\" | \"Rb\" | \"RB\" shortbytes ::= \"'\" shortbytesitem* \"'\" | '\"' shortbytesitem* '\"' longbytes ::= \"'''\" longbytesitem* \"'''\" | '\"\"\"' longbytesitem* '\"\"\"' shortbytesitem ::= shortbyteschar | bytesescapeseq longbytesitem ::= longbyteschar | bytesescapeseq shortbyteschar ::= <any ASCII character except \"\\\" or newline or the quote> longbyteschar ::= <any ASCII character except \"\\\"> bytesescapeseq ::= \"\\\" <any ASCII character> bytesprefix shortbytes longbytes shortbytesitem shortbytesitem longbytesitem longbytesitem shortbyteschar bytesescapeseq longbyteschar bytesescapeseq stringprefix bytesprefix ' \" \\ n \\n 'b' 'B' bytes str 'r' 'R' '\\U' '\\u' 'rb' 'br' u'value' 'f' 'F' 'f' 'r' 'b' 'u' ' \" 'r' 'R' \\ \\\\ \\ \\' ' \\\" \" \\a \\b \\f \\n \\r \\t \\v \\ooo \\xhh \\N{name} \\uxxxx \\Uxxxxxxxx >>> 'This string will not include \\.",
  "title": "2. Lexical analysis.13.5",
  "section": "python_official",
  "subsection": "reference",
  "chunk_index": 19,
  "start_char": 36488,
  "end_char": 39126,
  "token_count": 746,
  "metadata": {
    "original_file": "data/raw/documentation_test/python_official/python_official_reference_99fb26420c3873aa.md",
    "chunk_method": "paragraph_based",
    "overlap_chars": 100,
    "processing_date": "2025-06-11T23:57:25.408635"
  },
  "file_path": "data/processed_test/chunks/python_official_python_official_reference_99fb26420c3873aa_898565d1500b_chunk_019.txt"
}