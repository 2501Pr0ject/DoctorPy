"""
Scripts de d√©ploiement et configuration Prefect pour DoctorPy
"""

import sys
import os
from pathlib import Path
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta
from prefect import flow, get_run_logger
from prefect.deployments import Deployment
from prefect.server.schemas.schedules import CronSchedule, IntervalSchedule

# Ajouter le r√©pertoire racine au path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

# Import des workflows
from .data_pipeline import update_knowledge_base, rag_quick_update, rag_full_pipeline
from .maintenance import daily_maintenance, weekly_maintenance, emergency_maintenance
from .analytics import generate_analytics, health_check_flow


def create_deployments():
    """
    Cr√©er tous les d√©ploiements Prefect pour DoctorPy
    """
    deployments = []
    
    # ===== D√âPLOIEMENTS RAG PIPELINE =====
    
    # Pipeline RAG quotidien (mise √† jour incr√©mentale)
    daily_rag_deployment = Deployment.build_from_flow(
        flow=rag_quick_update,
        name="daily-rag-update",
        version="1.0",
        description="Mise √† jour quotidienne rapide de la base de connaissances",
        tags=["rag", "daily", "automatic"],
        schedule=CronSchedule(
            cron="0 2 * * *",  # Tous les jours √† 2h du matin
            timezone="Europe/Paris"
        ),
        parameters={
            "force_refresh": False,
            "max_documents": None
        },
        work_pool_name="default-agent-pool"
    )
    deployments.append(daily_rag_deployment)
    
    # Pipeline RAG hebdomadaire (mise √† jour compl√®te)
    weekly_rag_deployment = Deployment.build_from_flow(
        flow=rag_full_pipeline,
        name="weekly-rag-full-update",
        version="1.0",
        description="Mise √† jour hebdomadaire compl√®te avec validations",
        tags=["rag", "weekly", "complete", "validation"],
        schedule=CronSchedule(
            cron="0 1 * * 0",  # Dimanche √† 1h du matin
            timezone="Europe/Paris"
        ),
        parameters={
            "force_all": True,
            "notification_channels": ["log", "email"]
        },
        work_pool_name="default-agent-pool"
    )
    deployments.append(weekly_rag_deployment)
    
    # Pipeline RAG manuel (√† la demande)
    manual_rag_deployment = Deployment.build_from_flow(
        flow=update_knowledge_base,
        name="manual-rag-update",
        version="1.0",
        description="Mise √† jour manuelle de la base de connaissances",
        tags=["rag", "manual", "on-demand"],
        # Pas de schedule - d√©clenchement manuel
        parameters={
            "force_refresh": False,
            "force_reprocess": False,
            "force_regenerate_embeddings": False,
            "force_reindex": False,
            "skip_validation": False,
            "max_documents": None,
            "notification_channels": ["log", "email"]
        },
        work_pool_name="default-agent-pool"
    )
    deployments.append(manual_rag_deployment)
    
    # ===== D√âPLOIEMENTS MAINTENANCE =====
    
    # Maintenance quotidienne
    daily_maintenance_deployment = Deployment.build_from_flow(
        flow=daily_maintenance,
        name="daily-maintenance",
        version="1.0",
        description="Maintenance quotidienne automatis√©e",
        tags=["maintenance", "daily", "cleanup"],
        schedule=CronSchedule(
            cron="0 3 * * *",  # Tous les jours √† 3h du matin (apr√®s le RAG)
            timezone="Europe/Paris"
        ),
        parameters={
            "notification_channels": ["log"],
            "skip_backup": False,
            "skip_cleanup": False
        },
        work_pool_name="default-agent-pool"
    )
    deployments.append(daily_maintenance_deployment)
    
    # Maintenance hebdomadaire
    weekly_maintenance_deployment = Deployment.build_from_flow(
        flow=weekly_maintenance,
        name="weekly-maintenance",
        version="1.0",
        description="Maintenance hebdomadaire approfondie",
        tags=["maintenance", "weekly", "deep-cleanup"],
        schedule=CronSchedule(
            cron="0 4 * * 0",  # Dimanche √† 4h du matin (apr√®s le RAG complet)
            timezone="Europe/Paris"
        ),
        parameters={
            "notification_channels": ["log", "email"],
            "include_deep_cleanup": True,
            "include_optimization": True
        },
        work_pool_name="default-agent-pool"
    )
    deployments.append(weekly_maintenance_deployment)
    
    # Maintenance d'urgence (manuel)
    emergency_maintenance_deployment = Deployment.build_from_flow(
        flow=emergency_maintenance,
        name="emergency-maintenance",
        version="1.0",
        description="Maintenance d'urgence pour probl√®mes critiques",
        tags=["maintenance", "emergency", "critical"],
        # Pas de schedule - d√©clenchement manuel uniquement
        parameters={
            "issue_description": "Probl√®me critique d√©tect√©",
            "notification_channels": ["log", "email"],
            "force_restart_services": False
        },
        work_pool_name="default-agent-pool"
    )
    deployments.append(emergency_maintenance_deployment)
    
    # ===== D√âPLOIEMENTS MONITORING =====
    
    # V√©rification de sant√© toutes les heures
    hourly_health_check_deployment = Deployment.build_from_flow(
        flow=health_check_flow,
        name="hourly-health-check",
        version="1.0",
        description="V√©rification de sant√© toutes les heures",
        tags=["monitoring", "health", "hourly"],
        schedule=CronSchedule(
            cron="0 * * * *",  # Toutes les heures
            timezone="Europe/Paris"
        ),
        parameters={
            "alert_on_degraded": True,
            "notification_channels": ["log"],
            "detailed_analysis": False
        },
        work_pool_name="default-agent-pool"
    )
    deployments.append(hourly_health_check_deployment)
    
    # V√©rification de sant√© d√©taill√©e (4 fois par jour)
    detailed_health_check_deployment = Deployment.build_from_flow(
        flow=health_check_flow,
        name="detailed-health-check",
        version="1.0",
        description="V√©rification de sant√© d√©taill√©e 4 fois par jour",
        tags=["monitoring", "health", "detailed"],
        schedule=CronSchedule(
            cron="0 */6 * * *",  # Toutes les 6 heures
            timezone="Europe/Paris"
        ),
        parameters={
            "alert_on_degraded": True,
            "notification_channels": ["log", "email"],
            "detailed_analysis": True
        },
        work_pool_name="default-agent-pool"
    )
    deployments.append(detailed_health_check_deployment)
    
    # ===== D√âPLOIEMENTS ANALYTICS =====
    
    # Rapport quotidien
    daily_analytics_deployment = Deployment.build_from_flow(
        flow=generate_analytics,
        name="daily-analytics-report",
        version="1.0",
        description="G√©n√©ration du rapport analytique quotidien",
        tags=["analytics", "daily", "report"],
        schedule=CronSchedule(
            cron="0 8 * * *",  # Tous les jours √† 8h du matin
            timezone="Europe/Paris"
        ),
        parameters={
            "report_type": "daily",
            "notification_channels": ["log", "email"],
            "include_health_check": True
        },
        work_pool_name="default-agent-pool"
    )
    deployments.append(daily_analytics_deployment)
    
    # Rapport hebdomadaire
    weekly_analytics_deployment = Deployment.build_from_flow(
        flow=generate_analytics,
        name="weekly-analytics-report",
        version="1.0",
        description="G√©n√©ration du rapport analytique hebdomadaire",
        tags=["analytics", "weekly", "report"],
        schedule=CronSchedule(
            cron="0 9 * * 1",  # Lundi √† 9h du matin
            timezone="Europe/Paris"
        ),
        parameters={
            "report_type": "weekly",
            "notification_channels": ["log", "email"],
            "include_health_check": True
        },
        work_pool_name="default-agent-pool"
    )
    deployments.append(weekly_analytics_deployment)
    
    # Rapport mensuel
    monthly_analytics_deployment = Deployment.build_from_flow(
        flow=generate_analytics,
        name="monthly-analytics-report",
        version="1.0",
        description="G√©n√©ration du rapport analytique mensuel",
        tags=["analytics", "monthly", "report"],
        schedule=CronSchedule(
            cron="0 10 1 * *",  # 1er de chaque mois √† 10h
            timezone="Europe/Paris"
        ),
        parameters={
            "report_type": "monthly",
            "notification_channels": ["log", "email"],
            "include_health_check": True
        },
        work_pool_name="default-agent-pool"
    )
    deployments.append(monthly_analytics_deployment)
    
    return deployments


def deploy_all_workflows():
    """
    D√©ployer tous les workflows Prefect
    """
    print("üöÄ D√©ploiement des workflows Prefect pour DoctorPy...")
    
    deployments = create_deployments()
    
    success_count = 0
    error_count = 0
    
    for deployment in deployments:
        try:
            print(f"üì§ D√©ploiement de {deployment.name}...")
            deployment_id = deployment.apply()
            print(f"‚úÖ {deployment.name} d√©ploy√© avec succ√®s (ID: {deployment_id})")
            success_count += 1
        except Exception as e:
            print(f"‚ùå Erreur lors du d√©ploiement de {deployment.name}: {str(e)}")
            error_count += 1
    
    print(f"\nüìä R√©sum√© du d√©ploiement:")
    print(f"   ‚úÖ Succ√®s: {success_count}")
    print(f"   ‚ùå Erreurs: {error_count}")
    print(f"   üì¶ Total: {len(deployments)}")
    
    if error_count == 0:
        print("\nüéâ Tous les workflows ont √©t√© d√©ploy√©s avec succ√®s!")
        print_deployment_summary()
    else:
        print(f"\n‚ö†Ô∏è {error_count} d√©ploiement(s) ont √©chou√©. V√©rifiez la configuration Prefect.")


def print_deployment_summary():
    """
    Afficher un r√©sum√© des d√©ploiements cr√©√©s
    """
    print("\nüìã R√©sum√© des workflows d√©ploy√©s:")
    
    print("\nüîÑ RAG Pipeline:")
    print("   ‚Ä¢ daily-rag-update: Mise √† jour quotidienne (2h00)")
    print("   ‚Ä¢ weekly-rag-full-update: Mise √† jour compl√®te (Dimanche 1h00)")
    print("   ‚Ä¢ manual-rag-update: D√©clenchement manuel")
    
    print("\nüßπ Maintenance:")
    print("   ‚Ä¢ daily-maintenance: Nettoyage quotidien (3h00)")
    print("   ‚Ä¢ weekly-maintenance: Maintenance approfondie (Dimanche 4h00)")
    print("   ‚Ä¢ emergency-maintenance: Maintenance d'urgence (manuel)")
    
    print("\nü©∫ Monitoring:")
    print("   ‚Ä¢ hourly-health-check: V√©rification toutes les heures")
    print("   ‚Ä¢ detailed-health-check: V√©rification d√©taill√©e (toutes les 6h)")
    
    print("\nüìä Analytics:")
    print("   ‚Ä¢ daily-analytics-report: Rapport quotidien (8h00)")
    print("   ‚Ä¢ weekly-analytics-report: Rapport hebdomadaire (Lundi 9h00)")
    print("   ‚Ä¢ monthly-analytics-report: Rapport mensuel (1er du mois 10h00)")


def create_prefect_config():
    """
    Cr√©er la configuration Prefect pour DoctorPy
    """
    config = {
        "prefect": {
            "api": {
                "url": "http://localhost:4200/api"
            },
            "cloud": {
                "api": "https://api.prefect.cloud/api/accounts/[ACCOUNT_ID]/workspaces/[WORKSPACE_ID]"
            },
            "server": {
                "analytics": False
            }
        },
        "logging": {
            "level": "INFO",
            "formatters": {
                "standard": {
                    "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
                }
            }
        },
        "flows": {
            "work_pool": "default-agent-pool",
            "storage": "./data/prefect",
            "results_storage": "./data/prefect/results"
        }
    }
    
    config_file = Path("prefect_config.yaml")
    
    import yaml
    with open(config_file, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
    
    print(f"üìÑ Configuration Prefect cr√©√©e: {config_file}")
    return config_file


def setup_prefect_environment():
    """
    Configurer l'environnement Prefect pour DoctorPy
    """
    print("üîß Configuration de l'environnement Prefect...")
    
    # Cr√©er les r√©pertoires n√©cessaires
    directories = [
        "data/prefect",
        "data/prefect/results", 
        "data/prefect/flows",
        "data/prefect/deployments",
        "logs/prefect"
    ]
    
    for directory in directories:
        Path(directory).mkdir(parents=True, exist_ok=True)
        print(f"üìÅ R√©pertoire cr√©√©: {directory}")
    
    # Cr√©er la configuration
    config_file = create_prefect_config()
    
    # Cr√©er un script de d√©marrage
    startup_script = Path("start_prefect.sh")
    startup_content = """#!/bin/bash

# Script de d√©marrage Prefect pour DoctorPy

echo "üöÄ D√©marrage de Prefect pour DoctorPy..."

# D√©finir les variables d'environnement
export PREFECT_API_URL="http://localhost:4200/api"
export PREFECT_LOGGING_LEVEL="INFO"

# D√©marrer le serveur Prefect en arri√®re-plan
echo "üñ•Ô∏è D√©marrage du serveur Prefect..."
prefect server start --host 0.0.0.0 --port 4200 &
SERVER_PID=$!

# Attendre que le serveur d√©marre
sleep 10

# Cr√©er l'agent de travail
echo "ü§ñ Cr√©ation de l'agent de travail..."
prefect work-pool create default-agent-pool --type process &
POOL_PID=$!

# Attendre que le pool soit cr√©√©
sleep 5

# D√©marrer l'agent
echo "‚ñ∂Ô∏è D√©marrage de l'agent..."
prefect agent start --pool default-agent-pool &
AGENT_PID=$!

echo "‚úÖ Prefect d√©marr√© avec succ√®s!"
echo "üåê Interface web: http://localhost:4200"
echo "üìä Dashboard: http://localhost:4200/dashboard"

# Garder le script en vie
echo "üîÑ Prefect en cours d'ex√©cution... (Ctrl+C pour arr√™ter)"
wait $SERVER_PID $POOL_PID $AGENT_PID
"""
    
    with open(startup_script, 'w', encoding='utf-8') as f:
        f.write(startup_content)
    
    # Rendre le script ex√©cutable
    import stat
    startup_script.chmod(startup_script.stat().st_mode | stat.S_IEXEC)
    
    print(f"üìú Script de d√©marrage cr√©√©: {startup_script}")
    
    # Cr√©er un script de d√©ploiement
    deploy_script = Path("deploy_workflows.py")
    deploy_content = """#!/usr/bin/env python3
\"\"\"
Script de d√©ploiement des workflows Prefect pour DoctorPy
\"\"\"

import sys
from pathlib import Path

# Ajouter le r√©pertoire racine au path
sys.path.insert(0, str(Path(__file__).parent))

from scripts.workflows.deployment import deploy_all_workflows, setup_prefect_environment

if __name__ == "__main__":
    print("üöÄ D√©ploiement des workflows DoctorPy...")
    
    # Configurer l'environnement si n√©cessaire
    setup_prefect_environment()
    
    # D√©ployer tous les workflows
    deploy_all_workflows()
    
    print("\\n‚úÖ D√©ploiement termin√©!")
    print("\\nüîó Commandes utiles:")
    print("   prefect server start                    # D√©marrer le serveur")
    print("   prefect agent start --pool default      # D√©marrer l'agent")
    print("   prefect deployment run <nom>             # Ex√©cuter un workflow")
    print("   prefect flow-run list                    # Voir les ex√©cutions")
"""
    
    with open(deploy_script, 'w', encoding='utf-8') as f:
        f.write(deploy_content)
    
    deploy_script.chmod(deploy_script.stat().st_mode | stat.S_IEXEC)
    
    print(f"üéØ Script de d√©ploiement cr√©√©: {deploy_script}")
    
    # Cr√©er un fichier README pour Prefect
    readme_file = Path("PREFECT_README.md")
    readme_content = """# Prefect Configuration pour DoctorPy

## Vue d'ensemble

Ce projet utilise Prefect pour orchestrer les workflows de donn√©es RAG, maintenance et monitoring.

## Workflows Disponibles

### üîÑ RAG Pipeline
- **daily-rag-update**: Mise √† jour quotidienne (2h00)
- **weekly-rag-full-update**: Mise √† jour compl√®te (Dimanche 1h00)
- **manual-rag-update**: D√©clenchement manuel

### üßπ Maintenance
- **daily-maintenance**: Nettoyage quotidien (3h00)
- **weekly-maintenance**: Maintenance approfondie (Dimanche 4h00)
- **emergency-maintenance**: Maintenance d'urgence (manuel)

### ü©∫ Monitoring
- **hourly-health-check**: V√©rification toutes les heures
- **detailed-health-check**: V√©rification d√©taill√©e (toutes les 6h)

### üìä Analytics
- **daily-analytics-report**: Rapport quotidien (8h00)
- **weekly-analytics-report**: Rapport hebdomadaire (Lundi 9h00)
- **monthly-analytics-report**: Rapport mensuel (1er du mois 10h00)

## D√©marrage Rapide

1. **Installer Prefect**:
   ```bash
   pip install prefect>=2.14.0
   ```

2. **D√©marrer l'environnement**:
   ```bash
   ./start_prefect.sh
   ```

3. **D√©ployer les workflows**:
   ```bash
   python deploy_workflows.py
   ```

4. **Acc√©der √† l'interface web**:
   - URL: http://localhost:4200
   - Dashboard: http://localhost:4200/dashboard

## Commandes Utiles

```bash
# Voir tous les d√©ploiements
prefect deployment list

# Ex√©cuter un workflow manuellement
prefect deployment run "manual-rag-update"

# Voir l'historique des ex√©cutions
prefect flow-run list

# Voir les logs d'une ex√©cution
prefect flow-run logs <flow-run-id>

# Suspendre/reprendre un d√©ploiement
prefect deployment pause <deployment-name>
prefect deployment resume <deployment-name>
```

## Configuration des Notifications

### Email (SMTP)
```bash
export SMTP_HOST="smtp.gmail.com"
export SMTP_PORT="587"
export SMTP_USER="your-email@gmail.com"
export SMTP_PASSWORD="your-app-password"
export FROM_EMAIL="doctorpy@yourcompany.com"
export ALERT_EMAILS="admin@yourcompany.com,team@yourcompany.com"
```

### Slack
```bash
export SLACK_WEBHOOK_URL="https://hooks.slack.com/services/..."
```

### Webhook Personnalis√©
```bash
export NOTIFICATION_WEBHOOK_URL="https://api.yourcompany.com/notifications"
export WEBHOOK_TOKEN="your-api-token"
```

## Surveillance et Maintenance

- Les logs sont stock√©s dans `logs/prefect/`
- Les donn√©es Prefect sont dans `data/prefect/`
- Les rapports sont g√©n√©r√©s dans `data/reports/`
- Les notifications sont archiv√©es dans `data/notifications/`

## D√©pannage

### Probl√®mes Courants

1. **Erreur de connexion √† la base de donn√©es**:
   - V√©rifier que `data/databases/doctorpy.db` existe
   - V√©rifier les permissions de fichier

2. **ChromaDB indisponible**:
   - V√©rifier que `data/vector_store/` existe
   - Red√©marrer le workflow d'indexation

3. **Notifications non envoy√©es**:
   - V√©rifier les variables d'environnement
   - Tester la connectivit√© SMTP/Slack

### Maintenance d'Urgence

En cas de probl√®me critique:

```bash
# Ex√©cuter la maintenance d'urgence
prefect deployment run "emergency-maintenance" --param issue_description="Description du probl√®me"

# Suspendre tous les d√©ploiements automatiques
prefect deployment pause --all

# Reprendre apr√®s r√©solution
prefect deployment resume --all
```
"""
    
    with open(readme_file, 'w', encoding='utf-8') as f:
        f.write(readme_content)
    
    print(f"üìö Documentation cr√©√©e: {readme_file}")
    
    print("\n‚úÖ Environnement Prefect configur√© avec succ√®s!")
    print("\nüîó √âtapes suivantes:")
    print("   1. ./start_prefect.sh          # D√©marrer Prefect")
    print("   2. python deploy_workflows.py  # D√©ployer les workflows")
    print("   3. http://localhost:4200       # Acc√©der √† l'interface")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Gestion des d√©ploiements Prefect pour DoctorPy")
    parser.add_argument("--setup", action="store_true", help="Configurer l'environnement Prefect")
    parser.add_argument("--deploy", action="store_true", help="D√©ployer tous les workflows")
    parser.add_argument("--all", action="store_true", help="Setup + Deploy")
    
    args = parser.parse_args()
    
    if args.setup or args.all:
        setup_prefect_environment()
    
    if args.deploy or args.all:
        deploy_all_workflows()
    
    if not any(vars(args).values()):
        print("Utilisez --setup, --deploy ou --all")
        parser.print_help()